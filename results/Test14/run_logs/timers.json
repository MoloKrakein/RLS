{
    "name": "root",
    "gauges": {
        "MoveToPlayer.Policy.Entropy.mean": {
            "value": 0.32207968831062317,
            "min": 0.32207968831062317,
            "max": 1.580285668373108,
            "count": 10
        },
        "MoveToPlayer.Policy.Entropy.sum": {
            "value": 16101.4072265625,
            "min": 16101.4072265625,
            "max": 79418.8359375,
            "count": 10
        },
        "MoveToPlayer.Environment.EpisodeLength.mean": {
            "value": 7.2635927945794085,
            "min": 7.2635927945794085,
            "max": 316.0612244897959,
            "count": 10
        },
        "MoveToPlayer.Environment.EpisodeLength.sum": {
            "value": 43952.0,
            "min": 43952.0,
            "max": 51510.0,
            "count": 10
        },
        "MoveToPlayer.Step.mean": {
            "value": 499998.0,
            "min": 49936.0,
            "max": 499998.0,
            "count": 10
        },
        "MoveToPlayer.Step.sum": {
            "value": 499998.0,
            "min": 49936.0,
            "max": 499998.0,
            "count": 10
        },
        "MoveToPlayer.Policy.ExtrinsicValueEstimate.mean": {
            "value": 2.071636438369751,
            "min": -11.122638702392578,
            "max": 2.071636438369751,
            "count": 10
        },
        "MoveToPlayer.Policy.ExtrinsicValueEstimate.sum": {
            "value": 12535.47265625,
            "min": -9509.8564453125,
            "max": 12535.47265625,
            "count": 10
        },
        "MoveToPlayer.Environment.CumulativeReward.mean": {
            "value": 2.232482479812882,
            "min": -30.135335398369094,
            "max": 2.232482479812882,
            "count": 10
        },
        "MoveToPlayer.Environment.CumulativeReward.sum": {
            "value": 13508.751485347748,
            "min": -4429.894303560257,
            "max": 13508.751485347748,
            "count": 10
        },
        "MoveToPlayer.Policy.ExtrinsicReward.mean": {
            "value": 2.232482479812882,
            "min": -30.135335398369094,
            "max": 2.232482479812882,
            "count": 10
        },
        "MoveToPlayer.Policy.ExtrinsicReward.sum": {
            "value": 13508.751485347748,
            "min": -4429.894303560257,
            "max": 13508.751485347748,
            "count": 10
        },
        "MoveToPlayer.Losses.PolicyLoss.mean": {
            "value": 0.036666361275129025,
            "min": 0.03382173532713205,
            "max": 0.036666361275129025,
            "count": 10
        },
        "MoveToPlayer.Losses.PolicyLoss.sum": {
            "value": 0.1833318063756451,
            "min": 0.13771160166710616,
            "max": 0.1833318063756451,
            "count": 10
        },
        "MoveToPlayer.Losses.ValueLoss.mean": {
            "value": 0.01868028943799436,
            "min": 0.01868028943799436,
            "max": 26.99212186038494,
            "count": 10
        },
        "MoveToPlayer.Losses.ValueLoss.sum": {
            "value": 0.0934014471899718,
            "min": 0.0934014471899718,
            "max": 107.96848744153976,
            "count": 10
        },
        "MoveToPlayer.Policy.LearningRate.mean": {
            "value": 1.6833694388800003e-05,
            "min": 1.6833694388800003e-05,
            "max": 0.00028457925514025005,
            "count": 10
        },
        "MoveToPlayer.Policy.LearningRate.sum": {
            "value": 8.416847194400002e-05,
            "min": 8.416847194400002e-05,
            "max": 0.0012840174719942,
            "count": 10
        },
        "MoveToPlayer.Policy.Epsilon.mean": {
            "value": 0.10561119999999999,
            "min": 0.10561119999999999,
            "max": 0.19485975000000003,
            "count": 10
        },
        "MoveToPlayer.Policy.Epsilon.sum": {
            "value": 0.528056,
            "min": 0.5003124,
            "max": 0.9280058000000002,
            "count": 10
        },
        "MoveToPlayer.Policy.Beta.mean": {
            "value": 6.555088000000002e-05,
            "min": 6.555088000000002e-05,
            "max": 0.0009491115249999997,
            "count": 10
        },
        "MoveToPlayer.Policy.Beta.sum": {
            "value": 0.00032775440000000006,
            "min": 0.00032775440000000006,
            "max": 0.00428725742,
            "count": 10
        },
        "MoveToPlayer.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "MoveToPlayer.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1742202704",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\trist\\anaconda3\\envs\\mlagents\\Scripts\\mlagents-learn .\\config\\trainer_config.yaml --run-id Test14",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.6.0+cu126",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1742203581"
    },
    "total": 876.7972330000193,
    "count": 1,
    "self": 0.009393200045451522,
    "children": {
        "run_training.setup": {
            "total": 0.11467089998768643,
            "count": 1,
            "self": 0.11467089998768643
        },
        "TrainerController.start_learning": {
            "total": 876.6731688999862,
            "count": 1,
            "self": 1.3731906974862795,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.755307799990987,
                    "count": 1,
                    "self": 8.755307799990987
                },
                "TrainerController.advance": {
                    "total": 866.4127734025533,
                    "count": 67146,
                    "self": 1.2296934085316025,
                    "children": {
                        "env_step": {
                            "total": 578.8794449979032,
                            "count": 67146,
                            "self": 419.6698615025671,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 158.41327989668935,
                                    "count": 67146,
                                    "self": 2.3989626961993054,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 156.01431720049004,
                                            "count": 41670,
                                            "self": 156.01431720049004
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.796303598646773,
                                    "count": 67146,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 867.6066584024229,
                                            "count": 67146,
                                            "is_parallel": true,
                                            "self": 512.8502600993088,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.000520200002938509,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00023110001347959042,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00028909998945891857,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00028909998945891857
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 354.7558781031112,
                                                    "count": 67146,
                                                    "is_parallel": true,
                                                    "self": 7.357399394415552,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 7.252485701115802,
                                                            "count": 67146,
                                                            "is_parallel": true,
                                                            "self": 7.252485701115802
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 318.9514371016994,
                                                            "count": 67146,
                                                            "is_parallel": true,
                                                            "self": 318.9514371016994
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 21.194555905880406,
                                                            "count": 67146,
                                                            "is_parallel": true,
                                                            "self": 8.94024840532802,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 12.254307500552386,
                                                                    "count": 268584,
                                                                    "is_parallel": true,
                                                                    "self": 12.254307500552386
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 286.3036349961185,
                            "count": 67146,
                            "self": 1.6336588001868222,
                            "children": {
                                "process_trajectory": {
                                    "total": 112.03932299598819,
                                    "count": 67146,
                                    "self": 111.93122779598343,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.10809520000475459,
                                            "count": 1,
                                            "self": 0.10809520000475459
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 172.63065319994348,
                                    "count": 48,
                                    "self": 99.85704569905647,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 72.77360750088701,
                                            "count": 4800,
                                            "self": 72.77360750088701
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.999769877642393e-07,
                    "count": 1,
                    "self": 7.999769877642393e-07
                },
                "TrainerController._save_models": {
                    "total": 0.1318961999786552,
                    "count": 1,
                    "self": 0.016062999988207594,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.11583319999044761,
                            "count": 1,
                            "self": 0.11583319999044761
                        }
                    }
                }
            }
        }
    }
}